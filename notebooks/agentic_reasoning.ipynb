{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sou.reasoning.run_reasoning import run_reasoning_loop, initialize_agents\n",
    "from sou.reasoning.sequence import Sequence\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nano-graphrag:Creating working directory ./nano_graphrag_cache_2025-03-21-18:26:46\n",
      "INFO:nano-graphrag:Load KV full_docs with 0 data\n",
      "INFO:nano-graphrag:Load KV text_chunks with 0 data\n",
      "INFO:nano-graphrag:Load KV llm_response_cache with 0 data\n",
      "INFO:nano-graphrag:Load KV community_reports with 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': './nano_graphrag_cache_2025-03-21-18:26:46/vdb_entities.json'} 0 data\n",
      "#0 building with \"desktop-linux\" instance using docker driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 134B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load metadata for docker.io/library/python:3.11-slim\n",
      "#2 ...\n",
      "\n",
      "#3 [auth] library/python:pull token for registry-1.docker.io\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#2 [internal] load metadata for docker.io/library/python:3.11-slim\n",
      "#2 DONE 1.4s\n",
      "\n",
      "#4 [internal] load .dockerignore\n",
      "#4 transferring context: 2B done\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [1/2] FROM docker.io/library/python:3.11-slim@sha256:7029b00486ac40bed03e36775b864d3f3d39dcbdf19cd45e6a52d541e6c178f0\n",
      "#5 resolve docker.io/library/python:3.11-slim@sha256:7029b00486ac40bed03e36775b864d3f3d39dcbdf19cd45e6a52d541e6c178f0 done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [2/2] WORKDIR /app\n",
      "#6 CACHED\n",
      "\n",
      "#7 exporting to image\n",
      "#7 exporting layers done\n",
      "#7 exporting manifest sha256:362bdd3321070589fc8faa49fed1c89ebcdfbcea4520e2d4827ed96041f5e928 done\n",
      "#7 exporting config sha256:dd895b31d859226dcc122566d754a8b41064ed19b1baa3942d8b359e7c4644ad done\n",
      "#7 exporting attestation manifest sha256:8a68cdb183b3f0f6008e90980f2e4238ede83e4a7746a5b571c5879c4c989de7 0.0s done\n",
      "#7 exporting manifest list sha256:332831990465f1a8b58475f2afe1d760fb09dc189cf41baf3e973e80ff5bf321 done\n",
      "#7 naming to docker.io/library/python_executor:latest done\n",
      "#7 unpacking to docker.io/library/python_executor:latest done\n",
      "#7 DONE 0.0s\n"
     ]
    }
   ],
   "source": [
    "from sou.reasoning.config import ReasoningSettings\n",
    "\n",
    "sequence = Sequence(\n",
    "    question=\"What is the capital of France?\",\n",
    ")\n",
    "\n",
    "settings = ReasoningSettings(\n",
    "    model_name=\"gpt-4\",\n",
    "    use_rag_agent=True,\n",
    "    use_code_agent=True,\n",
    "    forcing_search=True,\n",
    ")\n",
    "\n",
    "agents = initialize_agents(settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['search_agent', 'code_agent', 'rag_agent'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SearchAgent] Gathering information for query: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nano-graphrag:[New Docs] inserting 5 docs\n",
      "INFO:nano-graphrag:[New Chunks] inserting 5 chunks\n",
      "INFO:nano-graphrag:[Entity Extraction]...\n",
      "INFO:nano-graphrag:Writing graph with 0 nodes, 0 edges\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SearchAgent] Analyzing data:\n",
      "[\"Log In test 1 of 5 noun (1) ˈtest Synonyms of test 1 a : a means of testing: such as (1) : something (such as a series of questions or exercises) for measuring the skill, knowledge, intelligence, capacities, or aptitudes of an individual or group (2) : a procedure, reaction, or reagent used to identify or characterize a substance or constituent b : a positive result in such a test 2 a(1) : a critical examination, observation, or evaluation : trial specifically : the procedure of submitting a statement to such conditions or operations as will lead to its proof or disproof or to its acceptance or rejection a test of a statistical hypothesis (2) : a basis for evaluation : criterion b : an ordeal or oath required as proof of conformity with a set of beliefs c chiefly British : cupel 3 : a result or value determined by testing 4 : test match test 2 of 5 verb tested; testing; tests transitive verb 1 : to put to test or proof : try —often used with out 2 : to require a doctrinal oath of intransitive verb 1 a : to undergo a test b : to be assigned a standing or evaluation on the basis of tests tested positive for cocaine the cake tested done 2 : to apply a test as a means of analysis or diagnosis —used with for test for mechanical aptitude testability ˌte-stə-ˈbi-lə-tē noun testable ˈte-stə-bəl adjective test 3 of 5 adjective 1 : of, relating to, or constituting a test 2 : subjected to, used for, or revealed by testing a test group test data test 4 of 5 noun (2) : an external hard or firm covering (such as a shell) of many invertebrates (such as a foraminifer or a mollusk) Test 5 of 5 abbreviation Testament Phrases test the waters or less commonly test the water : to make a preliminary test or survey (as of reaction or interest) before embarking on a course of action Synonyms Noun (1) essay experiment experimentation trial Verb sample try (out) See all Synonyms & Antonyms in Thesaurus Examples of test in a Sentence Noun (1) will need to run some tests on the blood sample to rule out blood poisoning applicants for the cashier's position must first take a simple math test Verb Weekly quizzes will test your understanding of the material. The students will all be tested again at the end of the school year. She tested positive for the disease. The water gets tested regularly.\", \"Log In test 1 of 5 noun (1) ˈtest Synonyms of test 1 a : a means of testing: such as (1) : something (such as a series of questions or exercises) for measuring the skill, knowledge, intelligence, capacities, or aptitudes of an individual or group (2) : a procedure, reaction, or reagent used to identify or characterize a substance or constituent b : a positive result in such a test 2 a(1) : a critical examination, observation, or evaluation : trial specifically : the procedure of submitting a statement to such conditions or operations as will lead to its proof or disproof or to its acceptance or rejection a test of a statistical hypothesis (2) : a basis for evaluation : criterion b : an ordeal or oath required as proof of conformity with a set of beliefs c chiefly British : cupel 3 : a result or value determined by testing 4 : test match test 2 of 5 verb tested; testing; tests transitive verb 1 : to put to test or proof : try —often used with out 2 : to require a doctrinal oath of intransitive verb 1 a : to undergo a test b : to be assigned a standing or evaluation on the basis of tests tested positive for cocaine the cake tested done 2 : to apply a test as a means of analysis or diagnosis —used with for test for mechanical aptitude testability ˌte-stə-ˈbi-lə-tē noun testable ˈte-stə-bəl adjective test 3 of 5 adjective 1 : of, relating to, or constituting a test 2 : subjected to, used for, or revealed by testing a test group test data test 4 of 5 noun (2) : an external hard or firm covering (such as a shell) of many invertebrates (such as a foraminifer or a mollusk) Test 5 of 5 abbreviation Testament Phrases test the waters or less commonly test the water : to make a preliminary test or survey (as of reaction or interest) before embarking on a course of action Synonyms Noun (1) essay experiment experimentation trial Verb sample try (out) See all Synonyms & Antonyms in Thesaurus Examples of test in a Sentence Noun (1) will need to run some tests on the blood sample to rule out blood poisoning applicants for the cashier's position must first take a simple math test Verb Weekly quizzes will test your understanding of the material. The students will all be tested again at the end of the school year. She tested positive for the disease. The water gets tested regularly.\", 'FAST.com speed test gives you an estimate of your current Internet speed. Download speed is most relevant for people who are consuming content on the Internet, and we want FAST.com to be a very simple and fast speed test. When you click the â\\x80\\x9cShow more infoâ\\x80\\x9d button, you can see your upload speed and connection latency (ping). FAST.com provides two different latency measurements for your Internet connection: â\\x80\\x9cunloadedâ\\x80\\x9d and â\\x80\\x9cloadedâ\\x80\\x9d with traffic. To calculate your Internet speed, FAST.com performs a series of downloads from and uploads to Netflix servers and calculates the maximum speed your Internet connection can provide.', '× Highspeedinternet.com Compare Providers Review Providers Resources Search Search Search × Search Search Compare Providers Review Providers Resources Internet Speed Test Test Your Download and Upload Speeds Loading Start Speed Test There was an error initializing the test. Connecting to a server ... Download Speed Upload Speed Latency (ping) Show more test details + Hide Test Details − Get Our Speed Test App Latency (ping) Provider - IP Address 2607:fb90:3c0c:f066:90c4:16d7:3894:d924 Server location - View Test history Compare Providers × Your Test History Our free speed test app will keep track of your test history plus troubleshoot your internet speed issues. Download speed The speed at which your device pulls data from the internet. Upload speed The speed at which your device sends data to the internet. Latency (ping) The time (measured in milliseconds) it takes for a signal to travel from your device to an internet server and back.', 'Ookla®, Speedtest®, and Speedtest Intelligence® are among the federally registered trademarks of Ookla, LLC and may only be used with explicit written permission.', 'Speedtest by Ookla - The Global Broadband Speed Test Apps Android Apple TV iOS macOS Windows Learn Glossary Guides FAQ Data Ookla Research™ Speedtest Awards™ Speedtest Global Index™ Speedtest Performance Directory™ Apps Methodology Press Ookla Advertise HELP Results History Settings Help Create Account Remove Speedtest.net Ads Speedtest® Account Advertise Speedtest Awards™ Speedtest Servers™ Speedtest Performance Directory™ Ziff Davis Ookla® Brands Downdetector® Ekahau® RootMetrics® Apps Android Apple TV iOS macOS Windows Languages العربية Deutsch English Español Français Bahasa Indonesia Italiano 日本語 한국어 Nederlands Polski Português Русский Svenska ไทย 中文(简体) 中文(繁體) © 2006-2025 Ookla, LLC., a Ziff Davis company. Ookla®, Speedtest®, and Speedtest Intelligence® are among the federally registered trademarks of Ookla, LLC and may only be used with explicit written permission.']\n",
      "[rag_agent] Inserting data into knowledge graph\n"
     ]
    },
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magents\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msearch_agent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Data challenge/sou/sou/agents/search_agent.py:66\u001b[0m, in \u001b[0;36mSearchAgent.run\u001b[0;34m(self, query, deep_search)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     65\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_information(query)\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_and_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m info\n",
      "File \u001b[0;32m~/Downloads/Data challenge/sou/sou/agents/search_agent.py:54\u001b[0m, in \u001b[0;36mSearchAgent.analyze_and_store\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Analyze the data and store relevant details into the knowledge graph\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# TODO: Implement the analysis logic here\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknowledge_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknowledge_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Stored data in KnowledgeGraph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/Data challenge/sou/sou/agents/graphrag_agent.py:34\u001b[0m, in \u001b[0;36mGraphRAGAgent.insert_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minsert_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Inserting data into knowledge graph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/site-packages/nano_graphrag/graphrag.py:207\u001b[0m, in \u001b[0;36mGraphRAG.insert\u001b[0;34m(self, string_or_strings)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minsert\u001b[39m(\u001b[38;5;28mself\u001b[39m, string_or_strings):\n\u001b[1;32m    206\u001b[0m     loop \u001b[38;5;241m=\u001b[39m always_get_an_event_loop()\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mainsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring_or_strings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/site-packages/nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/asyncio/futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/asyncio/tasks.py:277\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/site-packages/nano_graphrag/graphrag.py:296\u001b[0m, in \u001b[0;36mGraphRAG.ainsert\u001b[0;34m(self, string_or_strings)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# ---------- extract/summary entity and upsert to graph\u001b[39;00m\n\u001b[1;32m    295\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Entity Extraction]...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 296\u001b[0m maybe_new_kg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentity_extraction_func(\n\u001b[1;32m    297\u001b[0m     inserting_chunks,\n\u001b[1;32m    298\u001b[0m     knwoledge_graph_inst\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_entity_relation_graph,\n\u001b[1;32m    299\u001b[0m     entity_vdb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentities_vdb,\n\u001b[1;32m    300\u001b[0m     global_config\u001b[38;5;241m=\u001b[39masdict(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    301\u001b[0m )\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maybe_new_kg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo new entities found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/site-packages/nano_graphrag/_op.py:383\u001b[0m, in \u001b[0;36mextract_entities\u001b[0;34m(chunks, knwoledge_graph_inst, entity_vdb, global_config)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(maybe_nodes), \u001b[38;5;28mdict\u001b[39m(maybe_edges)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# use_llm_func is wrapped in ascynio.Semaphore, limiting max_async callings\u001b[39;00m\n\u001b[0;32m--> 383\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;241m*\u001b[39m[_process_single_content(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m ordered_chunks]\n\u001b[1;32m    385\u001b[0m )\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mprint\u001b[39m()  \u001b[38;5;66;03m# clear the progress bar\u001b[39;00m\n\u001b[1;32m    387\u001b[0m maybe_nodes \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/asyncio/tasks.py:349\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 349\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/asyncio/tasks.py:277\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/site-packages/nano_graphrag/_op.py:322\u001b[0m, in \u001b[0;36mextract_entities.<locals>._process_single_content\u001b[0;34m(chunk_key_dp)\u001b[0m\n\u001b[1;32m    320\u001b[0m content \u001b[38;5;241m=\u001b[39m chunk_dp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    321\u001b[0m hint_prompt \u001b[38;5;241m=\u001b[39m entity_extract_prompt\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcontext_base, input_text\u001b[38;5;241m=\u001b[39mcontent)\n\u001b[0;32m--> 322\u001b[0m final_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m use_llm_func(hint_prompt)\n\u001b[1;32m    324\u001b[0m history \u001b[38;5;241m=\u001b[39m pack_user_ass_to_openai_messages(hint_prompt, final_result)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m now_glean_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(entity_extract_max_gleaning):\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/site-packages/nano_graphrag/_utils.py:177\u001b[0m, in \u001b[0;36mlimit_async_func_call.<locals>.final_decro.<locals>.wait_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(waitting_time)\n\u001b[1;32m    176\u001b[0m __current_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 177\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    178\u001b[0m __current_size \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/site-packages/nano_graphrag/_llm.py:70\u001b[0m, in \u001b[0;36mgpt_4o_complete\u001b[0;34m(prompt, system_prompt, history_messages, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgpt_4o_complete\u001b[39m(\n\u001b[1;32m     68\u001b[0m     prompt, system_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, history_messages\u001b[38;5;241m=\u001b[39m[], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     69\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m openai_complete_if_cache(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     72\u001b[0m         prompt,\n\u001b[1;32m     73\u001b[0m         system_prompt\u001b[38;5;241m=\u001b[39msystem_prompt,\n\u001b[1;32m     74\u001b[0m         history_messages\u001b[38;5;241m=\u001b[39mhistory_messages,\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     76\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/site-packages/tenacity/asyncio/__init__.py:189\u001b[0m, in \u001b[0;36mAsyncRetrying.wraps.<locals>.async_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    188\u001b[0m async_wrapped\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m copy(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/site-packages/tenacity/asyncio/__init__.py:111\u001b[0m, in \u001b[0;36mAsyncRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/site-packages/tenacity/asyncio/__init__.py:153\u001b[0m, in \u001b[0;36mAsyncRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    151\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/site-packages/tenacity/_utils.py:99\u001b[0m, in \u001b[0;36mwrap_to_async_func.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs: typing\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/site-packages/tenacity/__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/site-packages/tenacity/asyncio/__init__.py:114\u001b[0m, in \u001b[0;36mAsyncRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    116\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/site-packages/nano_graphrag/_llm.py:42\u001b[0m, in \u001b[0;36mopenai_complete_if_cache\u001b[0;34m(model, prompt, system_prompt, history_messages, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;129m@retry\u001b[39m(\n\u001b[1;32m     35\u001b[0m     stop\u001b[38;5;241m=\u001b[39mstop_after_attempt(\u001b[38;5;241m5\u001b[39m),\n\u001b[1;32m     36\u001b[0m     wait\u001b[38;5;241m=\u001b[39mwait_exponential(multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     model, prompt, system_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, history_messages\u001b[38;5;241m=\u001b[39m[], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     41\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 42\u001b[0m     openai_async_client \u001b[38;5;241m=\u001b[39m \u001b[43mget_openai_async_client_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     hashing_kv: BaseKVStorage \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhashing_kv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     44\u001b[0m     messages \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/site-packages/nano_graphrag/_llm.py:23\u001b[0m, in \u001b[0;36mget_openai_async_client_instance\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m global_openai_async_client\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_openai_async_client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m     global_openai_async_client \u001b[38;5;241m=\u001b[39m \u001b[43mAsyncOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m global_openai_async_client\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic_reasoning1/lib/python3.11/site-packages/openai/_client.py:337\u001b[0m, in \u001b[0;36mAsyncOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    335\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    338\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    339\u001b[0m     )\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "agents['search_agent'].run(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sequence = run_reasoning_loop(agents, settings, sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sou.reasoning.run_reasoning import run_reasoning\n",
    "\n",
    "\n",
    "accuracy_train = 0\n",
    "final_results_train_complete = []\n",
    "repetition = 5\n",
    "for i in range(repetition):\n",
    "    # Reset the finished flag for each sequence\n",
    "    for j in range(len(active_sequences_train)):\n",
    "        active_sequences_train[j][\"finished\"] = False\n",
    "    # Run reasoning\n",
    "    sequences_train = run_reasoning(\n",
    "        filtered_data_train,\n",
    "        active_sequences_train,\n",
    "        forcing_research=True,\n",
    "        code_mode_name=\"gpt-4o\",\n",
    "        general_model_args=model_args,\n",
    "        tokenizer=tokenizer,\n",
    "        tavily_client=tavily_client,\n",
    "    )\n",
    "    final_results_train = [\n",
    "        active_sequences_train[i][\"final_result\"]\n",
    "        for i in range(len(active_sequences_train))\n",
    "    ]\n",
    "    print(f\"Final results: {final_results_train}\")\n",
    "\n",
    "    accuracy_train += sum(\n",
    "        [\n",
    "            1\n",
    "            for i in range(len(final_results_train))\n",
    "            if final_results_train[i] == train_df[\"answer\"][i]\n",
    "        ]\n",
    "    ) / len(final_results_train)\n",
    "    final_results_train_complete.append(final_results_train)\n",
    "\n",
    "accuracy_train /= repetition\n",
    "print(f\"Accuracy on training set: {accuracy_train}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sou.reasoning.run_reasoning import run_reasoning\n",
    "\n",
    "\n",
    "final_results_test_complete = []\n",
    "repetition = 5\n",
    "for i in range(repetition):\n",
    "    for j in range(len(active_sequences_test)):\n",
    "        active_sequences_test[j][\"finished\"] = False\n",
    "    sequences_test = run_reasoning(\n",
    "        filtered_data_test,\n",
    "        active_sequences_test,\n",
    "        forcing_research=True,\n",
    "        code_mode_name=\"gpt-4o\",\n",
    "        general_model_args=model_args,\n",
    "        tokenizer=tokenizer,\n",
    "        tavily_client=tavily_client,\n",
    "    )\n",
    "    final_results_test = [\n",
    "        active_sequences_test[i][\"final_result\"]\n",
    "        for i in range(len(active_sequences_test))\n",
    "    ]\n",
    "    print(f\"Final results: {final_results_test}\")\n",
    "    final_results_test_complete.append(final_results_test)\n",
    "\n",
    "\n",
    "print(\"final_results_test_complete\", final_results_test_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "final_results_test_complete = np.array(final_results_test_complete).T.tolist()\n",
    "\n",
    "\n",
    "def save_predictions_to_csv(predictions_list, filename):\n",
    "    \"\"\"Save formatted predictions to CSV.\"\"\"\n",
    "    header = [\"question_id\"] + [f\"prediction_{i + 1}\" for i in range(5)]\n",
    "\n",
    "    with open(filename, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "        for i, predictions in enumerate(predictions_list, start=1):\n",
    "            writer.writerow([i] + predictions)\n",
    "\n",
    "\n",
    "# Save the formatted predictions\n",
    "save_predictions_to_csv(\n",
    "    final_results_test_complete, filename=\"./output/predictions_test.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the capital of France?\"\n",
    "final_sequence = run_reasoning_loop(prompt, reasoning_settings=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_reasoning1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
